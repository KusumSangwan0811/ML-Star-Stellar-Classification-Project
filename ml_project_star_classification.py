# -*- coding: utf-8 -*-
"""ML_Project_Star_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-YnUIkjryh57tP0Lr27C51UGZPkhSg4M

# Star Stellar Classification ML Project

In astronomy, stellar classification is the classification of stars based on their spectral characteristics. The classification scheme of galaxies, quasars, and stars is one of the most fundamental in astronomy. The early cataloguing of stars and their distribution in the sky has led to the understanding that they make up our own galaxy and, following the distinction that Andromeda was a separate galaxy to our own, numerous galaxies began to be surveyed as more powerful telescopes were built. This datasat aims to classify stars, galaxies, and quasars based on their spectral characteristics.

#Content
The data consists of 100,000 observations of space taken by the SDSS (Sloan Digital Sky Survey). Every observation is described by 17 feature columns and 1 class column which identifies it to be either a star, galaxy or quasar.

obj_ID = Object Identifier, the unique value that identifies the object in the image catalog used by the CAS

alpha = Right Ascension angle (at J2000 epoch)

delta = Declination angle (at J2000 epoch)

u = Ultraviolet filter in the photometric system

g = Green filter in the photometric system

r = Red filter in the photometric system

i = Near Infrared filter in the photometric system

z = Infrared filter in the photometric system

run_ID = Run Number used to identify the specific scan

rereun_ID = Rerun Number to specify how the image was processed

cam_col = Camera column to identify the scanline within the run

field_ID = Field number to identify each field

spec_obj_ID = Unique ID used for optical spectroscopic objects (this means that
2 different observations with the same spec_obj_ID must share the output class)

class = object class (galaxy, star or quasar object)

redshift = redshift value based on the increase in wavelength

plate = plate ID, identifies each plate in SDSS

MJD = Modified Julian Date, used to indicate when a given piece of SDSS data was taken

fiber_ID = fiber ID that identifies the fiber that pointed the light at the focal plane in each observation

# Details related to this project

In this project, I will try to predict the class of star with various ML algorithms such as SVM Classifier, Navie Bayes Classifier, Random Forest Classifier and XGboost Classifier. The data is downloaded from (https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17?resource=download&select=star_classification.csv).

The following steps are taken in this work:


1. Downloading this dataset from Kaggle
2. Understanding the dataset, formulating the problem and describing the objective
3. Performing a exploratory data analysis, gathering insights, creating a training, & test split and finally preparing the data for modeling.
4. Training & evaluating the different machine learning models.
5. Comparing their performances.
6. Reporting the final performance of best model and showing sample predictions.

At last, summary of the work and links to references.
"""

!pip install opendatasets scikit-learn

"""# Installing required libraries"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sns
import plotly.express as ex
sns.set_style('whitegrid')
from sklearn.model_selection import train_test_split, cross_val_predict
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import plot_tree, export_text
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import time
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
# %matplotlib inline

SMALL_SIZE = 10
MEDIUM_SIZE = 12

plt.rc('font', size=SMALL_SIZE)
plt.rc('axes', titlesize=MEDIUM_SIZE)
plt.rc('axes', labelsize=MEDIUM_SIZE)
plt.rcParams['figure.dpi']=150

"""# Downloading and exploring data"""

dataset_url1 = 'https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17?resource=download&select=star_classification.csv'

import opendatasets as od
od.download(dataset_url1)

raw_df = pd.read_csv('stellar-classification-dataset-sdss17/star_classification.csv')
raw_df

raw_df.info()

raw_df.describe()

"""Column "class" is our target and it can have three values, thus, multiclass classification problem. We should get rid of columns containing ID and "plate" column, but lets just analysis further before making this decision.

# Data Cleaning, Preprocessing and Visualisation

We need to take care of min value of features u, g, and z as they seems like skewed enteries
"""

raw_df.head()



print(raw_df['u'].skew()) #to check the skewness of feature u
raw_df['u'].describe()

"""Observe that data in feature 'u' is very much skewed, So, let us fix that by replacing outliers by median of the feature."""

raw_df['u'] = np.where(raw_df['u'] <-100.0, raw_df['u'].median(), raw_df['u'])
print(raw_df['u'].skew())

print(raw_df['g'].skew())

print(raw_df['z'].skew())

"""Observe that the data in features 'g' and 'z' are very skewed.  Let us fix this issue, by replacing outliers with median."""

raw_df['g'] = np.where(raw_df['g'] <-100.0, raw_df['g'].median(),raw_df['g'])
print(raw_df['g'].skew())
raw_df['z'] = np.where(raw_df['z'] <-100.0, raw_df['z'].median(),raw_df['z'])
print(raw_df['z'].skew())

raw_df.describe()

raw_df.head()

raw_df['class'].value_counts()

sns.catplot(x = 'class', kind = 'count', data = raw_df,height=3)

ex.pie(raw_df,names='class',title='Proportion of different classes')

"""The data looks a little imbalanced, but for now lets just consider this and lets trains some models."""

raw_df.columns.values

#raw_df["class"]=[0 if i == "GALAXY" else 1 if i == "STAR" else 2 for i in raw_df["class"]]

raw_df.head()



# Correlation of other features with redshift

# Drop the 'class' feature
df_excluded_class = raw_df.drop(columns=['class'])

# Calculate the correlation matrix
corr_matrix = df_excluded_class.corr()

# Extract and sort the correlation values for 'redshift'
corr_redshift = corr_matrix["redshift"].sort_values(ascending=False)

# Display the sorted correlation values
print(corr_redshift)



"""Correlation of 'rerun_ID', 'cam_col', and 'field_ID' with 'redshift' is minimal. So, we choose to drop these columns"""

raw_df.drop(['rerun_ID', 'cam_col', 'field_ID'], axis=1, inplace=True)

raw_df.head(10)

fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(16, 4))
ax = sns.distplot(raw_df[raw_df['class']=='STAR'].redshift, bins = 30, ax = axes[0], kde = False)
ax.set_title('Star')
ax = sns.distplot(raw_df[raw_df['class']=='GALAXY'].redshift, bins = 30, ax = axes[1], kde = False)
ax.set_title('Galaxy')
ax = sns.distplot(raw_df[raw_df['class']=='QSO'].redshift, bins = 30, ax = axes[2], kde = False)
ax = ax.set_title('QSO')

plt.figure(figsize=(8,8))
sns.heatmap(raw_df.corr(),annot=True,linewidths=0.6,fmt=".2f",cmap="coolwarm")
plt.show()

"""Observe that obj_ID and run_ID correlation is 1, spec_obj_ID and plate correlation is 1, spec_obj_ID and MJD correlation is almost 1, and correlation of MJD and plate is almost 1. So, we can drop run_ID, spec_obj_ID and plate.

Also, see that correlation of alpha is almost 0 with all other features.

Note that the "MJD" feature represents Modified Julian Date.


"""

# Correlation of other features with redshift
corr = raw_df.corr()
corr["redshift"].sort_values(ascending=False)

raw_df.drop(['run_ID', 'spec_obj_ID', 'plate', 'alpha'], axis=1, inplace=True)

fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(16, 4))
fig.set_dpi(100)
ax = sns.heatmap(raw_df[raw_df['class']=='STAR'][['u', 'g', 'r', 'i', 'z']].corr(), ax = axes[0], cmap='coolwarm',annot=True)
ax.set_title('Star')
ax = sns.heatmap(raw_df[raw_df['class']=='GALAXY'][['u', 'g', 'r', 'i', 'z']].corr(), ax = axes[1], cmap='coolwarm',annot=True)
ax.set_title('Galaxy')
ax = sns.heatmap(raw_df[raw_df['class']=='QSO'][['u', 'g', 'r', 'i', 'z']].corr(), ax = axes[2], cmap='coolwarm',annot=True)
ax = ax.set_title('QSO')



updated_df = raw_df

"""# Numeric feature scaling, encoding of categorical column and data splitting"""

scaler = MinMaxScaler()
sdss = scaler.fit_transform(updated_df.drop('class', axis=1))

# encoding class labels to integers
le = LabelEncoder()
y_encoded = le.fit_transform(updated_df['class'])
updated_df['class'] = y_encoded

X_train, X_test, y_train, y_test = train_test_split(updated_df.drop('class', axis=1), updated_df['class'], test_size=0.25)

"""# K-nearest neighbour model training and prediction on test set"""

knn = KNeighborsClassifier()
training_start = time.perf_counter()
knn.fit(X_train, y_train)
training_end = time.perf_counter()
pred_train = knn.predict(X_train)
acc_knn_train = (pred_train == y_train).sum().astype(float) / len(pred_train)*100
print("K-Nearest Neighbors Classifier's prediction accuracy on training set is: %3.2f" % (acc_knn_train))
prediction_start = time.perf_counter()
preds = knn.predict(X_test)
prediction_end = time.perf_counter()
acc_knn = (preds == y_test).sum().astype(float) / len(preds)*100
knn_train_time = training_end-training_start
knn_prediction_time = prediction_end-prediction_start
print("K-Nearest Neighbors Classifier's prediction accuracy on test set is: %3.2f" % (acc_knn))
print("Time consumed for training: %4.3f seconds" % (knn_train_time))
print("Time consumed for prediction: %4.3f seconds" % (knn_prediction_time))

knn.score(X_test, y_test)

"""# Naive Bayes Model training and prediction on test set"""

gnb = GaussianNB()
training_start = time.perf_counter()
gnb.fit(X_train, y_train)
training_end = time.perf_counter()
preds_train = gnb.predict(X_train)
acc_gnb_train = (preds_train == y_train).sum().astype(float) / len(preds_train)*100
print("Gaussian Naive Bayes Classifier's prediction accuracy on training set is: %3.2f" % (acc_gnb_train))
prediction_start = time.perf_counter()
preds = gnb.predict(X_test)
prediction_end = time.perf_counter()
acc_gnb = (preds == y_test).sum().astype(float) / len(preds)*100
gnb_train_time = training_end-training_start
gnb_prediction_time = prediction_end-prediction_start
print("Gaussian Naive Bayes Classifier's prediction accuracy on testing set is: %3.2f" % (acc_gnb))
print("Time consumed for training: %4.3f seconds" % (gnb_train_time))
print("Time consumed for prediction: %4.3f seconds" % (gnb_prediction_time))

gnb.score(X_test, y_test)

"""# Decision Tree Classifier Model training and prediction on test set"""

dtc = DecisionTreeClassifier(random_state=42)
training_start = time.perf_counter()
dtc.fit(X_train, y_train)
training_end = time.perf_counter()
pred_train = dtc.predict(X_train)
acc_dtc_train = (pred_train == y_train).sum().astype(float) / len(pred_train)*100
print("Decision Tree Classifier's prediction accuracy on training set is: %3.2f" % (acc_dtc_train))
prediction_start = time.perf_counter()
preds = dtc.predict(X_test)
prediction_end = time.perf_counter()
acc_dtc = (preds == y_test).sum().astype(float) / len(preds)*100
dtc_train_time = training_end-training_start
dtc_prediction_time = prediction_end-prediction_start
print("Decision Tree Classifier's prediction accuracy on test set is: %3.2f" % (acc_dtc))
print("Time consumed for training: %4.3f seconds" % (dtc_train_time))
print("Time consumed for prediction: %4.3f seconds" % (dtc_prediction_time))

dtc.score(X_test, y_test)

"""# XG Boost Classifier Model training and prediction on test set"""

xgb = XGBClassifier(n_estimators=10)
training_start = time.perf_counter()
xgb.fit(X_train, y_train)
training_end = time.perf_counter()
pred_train = xgb.predict(X_train)
acc_xgb_train = (pred_train == y_train).sum().astype(float) / len(pred_train)*100
print("XGBoost's prediction accuracy on training set is: %3.2f" % (acc_xgb_train))
prediction_start = time.perf_counter()
preds = xgb.predict(X_test)
prediction_end = time.perf_counter()
acc_xgb = (preds == y_test).sum().astype(float) / len(preds)*100
xgb_train_time = training_end-training_start
xgb_prediction_time = prediction_end-prediction_start
print("XGBoost's prediction accuracy on testing set is: %3.2f" % (acc_xgb))
print("Time consumed for training: %4.3f" % (xgb_train_time))
print("Time consumed for prediction: %4.3f seconds" % (xgb_prediction_time))

xgb.score(X_test, y_test)

"""As the prediction accuracy for both of the training set and testing set is very good, this implies that our model is not overfitting and thus, our model is giving a good performance overall.

There is no high variance and thus, there is no overfitting issue.

# Random forest classifier Model training and prediction on test set
"""

rfc = RandomForestClassifier(n_estimators=10)
training_start = time.perf_counter()
rfc.fit(X_train, y_train)
training_end = time.perf_counter()
pred_train = rfc.predict(X_train)
acc_rfc_train = (pred_train == y_train).sum().astype(float) / len(pred_train)*100
print("Random Forest Classifier's prediction accuracy on training set is: %3.2f" % (acc_rfc_train))
prediction_start = time.perf_counter()
preds = rfc.predict(X_test)
prediction_end = time.perf_counter()
acc_rfc = (preds == y_test).sum().astype(float) / len(preds)*100
rfc_train_time = training_end-training_start
rfc_prediction_time = prediction_end-prediction_start
print("Random Forest Classifier's prediction accuracy on test set is: %3.2f" % (acc_rfc))
print("Time consumed for training: %4.3f seconds" % (rfc_train_time))
print("Time consumed for prediction: %4.3f seconds" % (rfc_prediction_time))

rfc.score(X_test, y_test)

"""# Support Vector Machine Classifier Model training and prediction on test set"""

svc = SVC()
training_start = time.perf_counter()
svc.fit(X_train, y_train)
training_end = time.perf_counter()
preds_train = svc.predict(X_test)
acc_svc_train = (preds_train == y_test).sum().astype(float) / len(preds_train)*100
print("Support Vector Machine Classifier's prediction accuracy of training set is: %3.2f" % (acc_svc_train))
prediction_start = time.perf_counter()
preds = svc.predict(X_test)
prediction_end = time.perf_counter()
acc_svc = (preds == y_test).sum().astype(float) / len(preds)*100
svc_train_time = training_end-training_start
svc_prediction_time = prediction_end-prediction_start
print("Support Vector Machine Classifier's prediction accuracy of test set is: %3.2f" % (acc_svc))
print("Time consumed for training: %4.3f seconds" % (svc_train_time))
print("Time consumed for prediction: %4.3f seconds" % (svc_prediction_time))

svc.score(X_test,y_test)

"""# Model Performances Comparison"""

results = pd.DataFrame({
    'Model': ['KNN', 'Naive Bayes', 'Decision Tree',
              'XGBoost', 'Random Forest','SVC'],
    'Train Score': [acc_knn_train, acc_gnb_train, acc_dtc_train, acc_xgb_train, acc_rfc_train, acc_svc_train],
    'Test Score': [acc_knn, acc_gnb, acc_dtc, acc_xgb, acc_rfc,acc_svc],
    'Runtime Training': [knn_train_time, gnb_train_time, dtc_train_time, xgb_train_time, rfc_train_time, svc_train_time],
    'Runtime Prediction': [knn_prediction_time, gnb_prediction_time, dtc_prediction_time, xgb_prediction_time, rfc_prediction_time, svc_prediction_time]})

result_df = results.sort_values(by='Test Score', ascending=False)
result_df = result_df.set_index('Model')
result_df

"""On comparing, we observe that Decision tree Classifier is one of the fastest and most accurate model.

We now do some hyperparameter tuning of Decision Tree Classifier to further improve its efficiency.
"""



"""# Hyperparamter Tuning Decision Tree Classifier"""

model = DecisionTreeClassifier(max_depth=3, random_state=42)
model.fit(X_train, y_train)

"""We can compute the accuracy of the model on the training and validation sets using model.score"""

model.score(X_train, y_train)

model.score(X_test, y_test)

"""Both the accuracy are 95% now. Lets make this better."""

model.classes_

# plt.figure(figsize=(80,20))
# plot_tree(model, feature_names=X_train.columns, filled=True, rounded=True, class_names=model.classes_);

model = DecisionTreeClassifier(max_depth=7, random_state=42).fit(X_train, y_train)
model.score(X_test, y_test)

model = DecisionTreeClassifier(max_depth=8, random_state=42).fit(X_train, y_train)
model.score(X_test, y_test)

"""The accuracy of the model for test set has increased by more than 2%."""

model = DecisionTreeClassifier(max_leaf_nodes=128, random_state=42)
model.fit(X_train, y_train)

model.score(X_train, y_train)

model.score(X_test, y_test)

model = DecisionTreeClassifier(max_depth=11,max_leaf_nodes=128, random_state=42)
model.fit(X_train, y_train)

model.score(X_train, y_train)

model.score(X_test, y_test)

"""Observe that the accuracy of the model has become flat and is no longer getting any better."""

best_model=model

"""## Saving the best trained model"""

import pickle

# Define the filename for the saved model
filename = 'best_model.pkl'

# Use pickle to save the trained model to a file
with open(filename, 'wb') as file:
    pickle.dump(best_model, file)

print(f"Model saved to {filename}")

"""To load the model back into your environment later, you can use the following code:"""

# Use pickle to load the trained model from the file
with open(filename, 'rb') as file:
    loaded_model = pickle.load(file)

print("Model loaded successfully")



"""# Summary and References

In this project, the Star Class dataset is used which consists of 100000 observations and 18 features. The aim is to classify stars based on various features, total feature (18 features defined). We have performed exploratory data analysis to gather insights, created a training, validation & test dataset and prepared the data for modeling. Then, we trained and evaluated different machine learning models such as k-NN Classifier, Navie Bayes Classifier, Random Forest Classifier and XGboost Classifier.  We have seen that some ML models performs extremly well. Finally, we compared the performance of models are evaluated on a test data.

The best model trained is Decision tree classifier model and done some hyperparameter tuning with an accuracy of 97.6% on test set.





#References

1. The dataset used for this project is obtained from Kaggle and at https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17?resource=download&select=star_classification.csv

2. https://jovian.com/learn/machine-learning-with-python-zero-to-gbms

3. https://jovian.com/kusum-sangwan/python-random-forests-assignment

4. https://www.geeksforgeeks.org/
"""